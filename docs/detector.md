# Детектор инструментов

Этот документ описывает, как в проект интегрирован модуль компьютерного зрения на основе Ultralytics YOLOv11, и какие настройки доступны.

## Архитектура

- Бэкенд использует `YoloDetectionClient`, объявленный в `backend/app/services/detection_client.py`.
- Клиент загружает веса `ml/best.pt` и названия классов из `ml/dataset.yaml` при старте приложения.
- Если модель не может быть загружена (файлы отсутствуют, PyTorch не установлен, устройство недоступно), система автоматически переходит на детерминированный `MockDetectionClient`, чтобы API оставалось работоспособным.
- В качестве альтернативы можно указать переменную `DETECTION_SERVICE_URL` и перенаправить вызовы в сторонний REST-сервис (`HttpDetectionClient`).

## Веса и классы

| Файл | Назначение |
| --- | --- |
| `ml/best.pt` | Предобученные веса YOLOv11. Разрешение обучения — 720. |
| `ml/dataset.yaml` | Список из 11 классов (инструментов) и пути до исходного датасета. |

Названия классов из YAML сопоставлены с внутренним каталогом инструментов. Любой прогноз с индексом, отсутствующим в каталоге, возвращается с `tool_id = null`.

## Переменные окружения

| Переменная | Значение по умолчанию | Описание |
| --- | --- | --- |
| `YOLO_MODEL_PATH` | `ml/best.pt` | Путь до весов модели. |
| `YOLO_DATASET_CONFIG` | `ml/dataset.yaml` | YAML с отображением индексов в названия. |
| `YOLO_CONFIDENCE_THRESHOLD` | `0.25` | Нижняя граница для `confidence`. |
| `YOLO_IMAGE_SIZE` | `720` | Значение `imgsz` во время инференса. |
| `YOLO_DEVICE` | `None` | Устройство: `cpu`, `cuda:0` и т. п. |
| `DETECTION_SERVICE_URL` | `None` | Если задана, используется HTTP-клиент вместо локальной модели. |

Все параметры можно задать через `.env`, системные переменные или перед запуском докер-контейнера.

## Использование локального детектора

1. Убедитесь, что зависимости установлены:
   ```bash
   pip install -r requirements.txt
   ```
2. Запустите бэкенд:
   ```bash
   uvicorn backend.app.main:app --reload
   ```
3. Получите сводку о задействованном бэкенде:
   ```bash
   curl -H "Authorization: Bearer <token>" \
        http://localhost:8000/api/vision/status
   ```
   Ответ содержит название backend (`yolo`, `mock`, `http`), параметры и список классов.
4. Отправьте изображение на проверку без создания сессии:
   ```bash
   curl -X POST \
        -H "Authorization: Bearer <token>" \
        -F "file=@sample.jpg" \
        http://localhost:8000/api/vision/detect
   ```
5. Ответ содержит массив `detections` с `tool_id`, `label` и `confidence`.

## Переключение на внешний сервис

1. Разверните собственный сервис с конечной точкой `POST /detect`, принимающей файл `file` и возвращающей JSON формата:
   ```json
   {"detections": [{"tool_id": "pliers", "label": "Пассатижи", "confidence": 0.92}]}
   ```
2. Перед запуском основного приложения экспортируйте переменную:
   ```bash
   export DETECTION_SERVICE_URL="http://vision-host:8080"
   ```
3. Перезапустите бэкенд. Теперь `HttpDetectionClient` будет использоваться вместо локального YOLO.

## Диагностика

- При старте приложения в логах появится сообщение о загрузке весов YOLO. Если видите предупреждение о возврате к заглушке, проверьте пути, наличие `torch`/`ultralytics` и права на файлы.
- Для ускорения инференса на GPU установите бинарники PyTorch с поддержкой CUDA и задайте `YOLO_DEVICE=cuda:0`.
- Локальные загрузки временно сохраняются в `data/uploads/` и удаляются после завершения запроса `/api/vision/detect`.
